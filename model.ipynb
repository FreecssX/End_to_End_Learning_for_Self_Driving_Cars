{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to End Learning for Self-Driving Cars 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy import array\n",
    "import time\n",
    "import math\n",
    "from datetime import timedelta\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "L2NormConst = 0.001\n",
    "learning_rate = 1e-4\n",
    "keep_prob = tf.placeholder(tf.float32) #drop_out参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.1))\n",
    "\n",
    "def bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))\n",
    "\n",
    "#卷积层\n",
    "def conv_relu(x, W, stride, b):\n",
    "    return tf.nn.relu(tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID') + b)\n",
    "#全连接层\n",
    "def matmul_relu(fc, W, b):\n",
    "    return tf.nn.relu(tf.matmul(fc, W) + b)\n",
    "\n",
    "with tf.name_scope('input_data'):\n",
    "    image = tf.placeholder(tf.float32, shape=[None, 66, 200, 3]) #输入为RGB图片\n",
    "    angle = tf.placeholder(tf.float32, shape=[None, 1]) #图片对应的转向角\n",
    "\n",
    "with tf.name_scope('convlayer'):\n",
    "    \n",
    "    #第一层卷积\n",
    "    W_conv1 = weight([5, 5, 3, 24])\n",
    "    b_conv1 = bias([24])\n",
    "    conv1 = conv_relu(image, W_conv1, 2, b_conv1)\n",
    "    \n",
    "    #第二层卷积\n",
    "    W_conv2 = weight([5, 5, 24, 36])\n",
    "    b_conv2 = bias([36])\n",
    "    conv2 = conv_relu(conv1, W_conv2, 2, b_conv2)\n",
    "\n",
    "    #第三层卷积\n",
    "    W_conv3 = weight([5, 5, 36, 48])\n",
    "    b_conv3 = bias([48])\n",
    "    conv3 = conv_relu(conv2, W_conv3, 2, b_conv3)\n",
    "\n",
    "    #第四层卷积\n",
    "    W_conv4 = weight([3, 3, 48, 64])\n",
    "    b_conv4 = bias([64])\n",
    "    conv4 = conv_relu(conv3, W_conv4, 1, b_conv4)\n",
    "    \n",
    "    #第五层卷积\n",
    "    W_conv5 = weight([3, 3, 64, 64])\n",
    "    b_conv5 = bias([64])\n",
    "    conv5 = conv_relu(conv4, W_conv5, 1, b_conv5)\n",
    "\n",
    "with tf.name_scope('full_connected_layer'):\n",
    "    \n",
    "    #展开成1维张量\n",
    "    conv5_flat = tf.reshape(conv5, [-1, 1152])\n",
    "    \n",
    "    #第一层全连接层\n",
    "    W_fc1 = weight([1152, 1164])\n",
    "    b_fc1 = bias([1164])\n",
    "    fc1 = matmul_relu(conv5_flat, W_fc1, b_fc1)\n",
    "    fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    #第二层全连接层\n",
    "    W_fc2 = weight([1164, 100])\n",
    "    b_fc2 = bias([100])\n",
    "    fc2 = matmul_relu(fc1, W_fc2, b_fc2)\n",
    "    fc2_drop = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    #第三层全连接层\n",
    "    W_fc3 = weight([100, 50])\n",
    "    b_fc3 = bias([50])\n",
    "    fc3 = matmul_relu(fc2, W_fc3, b_fc3)\n",
    "    fc3_drop = tf.nn.dropout(fc3, keep_prob)\n",
    "\n",
    "    #第四层全连接层\n",
    "    W_fc4 = weight([50, 10])\n",
    "    b_fc4 = bias([10])\n",
    "    fc4 = matmul_relu(fc3, W_fc4, b_fc4)\n",
    "    fc4_drop = tf.nn.dropout(fc4, keep_prob)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W_fc5 = weight([10, 1])\n",
    "    b_fc5 = bias([1])\n",
    "    angle_pred = tf.multiply(tf.atan(tf.matmul(fc4_drop, W_fc5) + b_fc5), 6)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    train_vars = tf.trainable_variables()\n",
    "    loss = tf.reduce_mean(tf.square(tf.subtract(angle_pred, angle))) \\\n",
    "    + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst #L2范数应对过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "angles = []\n",
    "\n",
    "#记录batch的位置\n",
    "train_batch_pointer = 0\n",
    "test_batch_pointer = 0\n",
    "\n",
    "#读取文件\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        images.append(\"driving_dataset/\" + line.split()[0])   #文件名\n",
    "        angles.append(float(line.split()[1]) * math.pi / 180) #将角度转为弧度\n",
    "\n",
    "\n",
    "num_images = len(images)\n",
    "\n",
    "combine = list(zip(images, angles)) #两个列表->元组->一个列表\n",
    "\n",
    "#使用随机数种子保存shuffle的状态\n",
    "random.seed(1)\n",
    "random.shuffle(combine)\n",
    "\n",
    "images, angles = zip(*combine) #一个列表->按一一对应的关系恢复为两个列表\n",
    "\n",
    "train_images = images[:int(num_images * 0.8)] #训练用图片\n",
    "train_angles = angles[:int(num_images * 0.8)]  #训练图片对应的角度\n",
    "\n",
    "test_images = images[-int(num_images * 0.2):] #测试用\n",
    "test_angles = angles[-int(num_images * 0.2):]\n",
    "\n",
    "num_train_images = len(train_images)\n",
    "num_test_images = len(test_images)\n",
    "\n",
    "def train_batch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    image_out = []\n",
    "    angle_out = []\n",
    "    for i in range(batch_size):\n",
    "        #将像素值归一化\n",
    "        image_out.append(scipy.misc.imresize(scipy.misc.imread(train_images[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        angle_out.append([train_angles[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return image_out, angle_out\n",
    "\n",
    "def test_batch(batch_size):\n",
    "    global test_batch_pointer\n",
    "    image_out = []\n",
    "    angle_out = []\n",
    "    for i in range(batch_size):\n",
    "        #将像素值归一化\n",
    "        image_out.append(scipy.misc.imresize(scipy.misc.imread(test_images[(test_batch_pointer + i) % num_test_images])[-150:], [66, 200]) / 255.0)\n",
    "        angle_out.append([test_angles[(test_batch_pointer + i) % num_test_images]])\n",
    "    test_batch_pointer += batch_size\n",
    "    return image_out, angle_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存记录\n",
    "saver = tf.train.Saver()\n",
    "save_path = './checkpoints'\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_iterations = 0 #在整个训练集上训练的次数\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    start_time = time.time()\n",
    "    global total_iterations\n",
    "    for i in range(total_iterations, total_iterations + num_iterations):\n",
    "        writer = tf.summary.FileWriter('./graph', tf.get_default_graph())\n",
    "        for j in range(int(num_images/batch_size)):\n",
    "            image_batch, angle_batch = train_batch(batch_size)\n",
    "            train.run(feed_dict={image: image_batch, angle: angle_batch, keep_prob: 0.8})\n",
    "            if j % 10 == 0:\n",
    "                image_batch, angle_batch = test_batch(batch_size)\n",
    "                loss_on_test = loss.eval(feed_dict={image:image_batch, angle: angle_batch, keep_prob: 1.0})\n",
    "                print(\"total_iterations: %d, Step: %d, Loss_On_Test: %g\" % (total_iterations , j, loss_on_test))\n",
    "        saver.save(sess=sess, save_path=save_path)\n",
    "    writer.close()\n",
    "    total_iterations += num_iterations\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(1) #训练一次"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
